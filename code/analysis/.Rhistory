corr_min  <- if (corr_type=='kendall') {
cor.fk(df$frequency, length)
} else cor.test(df$frequency,sort(df$length), method=corr_type, alternative = "less")$estimate %>% unname()
corr_min  <- if (corr_type=='kendall') {
cor.fk(df$frequency, df$length)
} else cor.test(df$frequency,sort(df$length), method=corr_type, alternative = "less")$estimate %>% unname()
corr_min
corr
cor.fk(df$frequency, sort(df$length))
corr_min
corr_min  <- if (corr_type=='kendall') {
cor.fk(df$frequency, sort(df$length))
} else cor.test(df$frequency,sort(df$length), method=corr_type, alternative = "less")$estimate %>% unname()
corr_min
# scores:
eta   <- Lmin/L
psi   <- (Lrand-L)/(Lrand-Lmin)
omega <- corr/corr_min
data.frame("language"=lang, "Lmin"=Lmin, "L"=L, "Lrand"=Lrand, "eta"=eta, "psi"=psi, "omega"=omega)
source('R_functions.R')
opt_df <- compute_optimality_scores_coll(collection,args[[1]],'characters')
opt_df
collection
corr_suffix
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1]
corr_df  <- read.csv(here('results',paste0('correlation_',collection,'_characters',corr_suffix,'.csv')))[-1]       # to remove if add tau and tau_min before
merged  <- merge(opt_df,corr_df, by = c('language','family','script')) %>%                           # to remove if add tau and tau_min before
select(-pvalue,-hb_pvalue) %>% mutate(corr_min = corr/omega) %>% arrange(family,script,language)    # to remove if add tau and tau_min before
source('R_functions.R')
source('R_functions.R')
opt_df <- compute_optimality_scores_coll(collection,args[[1]],'characters')
opt_df
write.csv(opt_df, here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))
length_defs
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,corr_suffix,'.csv')))[-1]
tau_df  <- read.csv(here('results',paste0('correlation_',collection,suffix,corr_suffix,'.csv')))[-1]
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1]
corr_df  <- read.csv(here('results',paste0('correlation_',collection,'_characters',corr_suffix,'.csv')))[-1]       # to remove if add tau and tau_min before
opt_df
corr_df
corr_df  <- read.csv(here('results',paste0('correlation_',collection,'_characters',corr_suffix,'.csv')))[-1] %>%
select(-pvalue,-hb_pvalue)
corr_df
merge(opt_df,corr_df, by = c('language'))
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1] %>%
arrange(family,script,language)
opt_df
merged <- merged[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1] %>%
arrange(family,script,language)
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
opt_df
print(xtable(opt_df,type = "latex"),
file = here('latex_tables',paste0(collection,"_opt_scores_characters",corr_suffix,".tex")),
include.rownames=FALSE, include.colnames=FALSE, only.contents = TRUE)
collection
langs_df <- if (collection == 'pud') langs_df_pud else if (collection == 'cv') langs_df_cv
sum_coll <- langs_df %>% mutate(dialect = NULL, iso_code = NULL) %>% rename(n = X.tokens, `T` = X.types)
A_coll   <- read.csv(here('results',paste0('alphabet_sisez_',collection,'.csv')))
sum_coll$A <- A_coll$A
sum_coll <- sum_coll[,c('language','family','script','A','n','T')] %>%
filter(stringr::str_detect(language,'-strokes') == F) %>% arrange(family,script,language)
sum_coll
write.csv(sum_coll,here('results',paste0('coll_summary_',collection,'.csv')))
print(xtable(sum_coll, type = "latex"),
file = here('latex_tables',paste0('coll_summary_',collection,".tex")),
include.rownames=FALSE,include.colnames=FALSE, only.contents = TRUE,
hline.after = c(nrow(sum_coll)))
read.csv(here("data/descriptive_tables/pud.csv"))
read.csv(here("data/descriptive_tables/common_voice.csv"))
read.csv(here("data/descriptive_tables/common_voice.csv"))
## cv
langs_df_cv <- read.csv(here("data/descriptive_tables/common_voice.csv")) %>%
filter(iso_code %!in% c('jpn','zho')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ina'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'ina'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'epo'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'ori'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'ell'), by = "iso_code") %>%
filter(dialect %!in% c('vallader','sursilv')) %>%
rows_update(tibble( iso_code = 'cnh',language = "Hakha Chin"), by = "language") %>%
rows_update(tibble( iso_code = 'sah',language = "Yakut"), by = "language")
read.csv(here("data/descriptive_tables/common_voice.csv")) %>%
filter(iso_code %!in% c('jpn','zho')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ina'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'ina'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'epo'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'ori'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'ell'), by = "iso_code") %>%
filter(dialect %!in% c('vallader','sursilv'))
## cv
langs_df_cv <- read.csv(here("data/descriptive_tables/common_voice.csv")) %>%
filter(iso_code %!in% c('jpn','zho')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'eo'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'el'), by = "iso_code") %>%
filter(dialect %!in% c('vallader','sursilv')) %>%
rows_update(tibble(iso_code = 'cnh',language = "Hakha Chin"), by = "language") %>%
rows_update(tibble(iso_code = 'sah',language = "Yakut"), by = "language")
langs_df_cv
collection
args
source('R_functions.R')
warnings()
args <- list('kendall','pud')
collection <- args[[2]]
corr_suffix <- paste0('_',args[[1]])
tau_df <- compute_corr(collection,args[[1]])
collection
langs_df <- if (collection == 'pud') langs_df_pud else if (collection == 'cv') langs_df_cv
cors <- mclapply(1:nrow(langs_df), function(i) {
iso_code <- langs_df$iso_code[i]
language <- langs_df$language[i]
print(iso_code)
dialect  <- ifelse(collection=='pud','',dialects_cv[i])
alternative <- if (stringr::str_detect(language,'-')) sub(".*-","",language) else NULL
df <- read_language(iso_code,collection,dialect,alternative) %>% mutate(rank=1:nrow(.))
if (collection == 'cv') {
df$length <- if (length == 'meanDuration') df$meanDuration else if (length == 'medianDuration') df$medianDuration else df$characters
}
res <- cor.test(df$frequency,df$length, method=corr_type, alternative = "less")
list("language"=language, "corr"=res$estimate, "pvalue"=res$p.value)
},mc.cores = 3)
1:nrow(langs_df)
i <- 1
iso_code <- langs_df$iso_code[i]
language <- langs_df$language[i]
print(iso_code)
dialect  <- ifelse(collection=='pud','',dialects_cv[i])
alternative <- if (stringr::str_detect(language,'-')) sub(".*-","",language) else NULL
df <- read_language(iso_code,collection,dialect,alternative) %>% mutate(rank=1:nrow(.))
iso_code
langs_df$iso_code
plotRanks <- function(a, b, title, labels.offset=0.1, arrow.len=0.1) {
old.par <- par(mar=c(1,1,1,1))
a <- rev(a)
b <- rev(b)
# Find the length of the vectors
len.1 <- length(a)
len.2 <- length(b)
# Plot two columns of equidistant points
plot(rep(1, len.1), 1:len.1, pch=20, cex=0.8,
xlim=c(0, 3), ylim=c(0, max(len.1, len.2)),
axes=F, xlab="", ylab="",main=title) # Remove axes and labels
points(rep(2, len.2), 1:len.2, pch=20, cex=0.8)
# Put labels next to each observation
text(rep(1-labels.offset, len.1), 1:len.1, a, cex=0.7)
text(rep(2+labels.offset, len.2), 1:len.2, b, cex=0.7)
# Map where the elements of a are in b
a.to.b <- match(a, b)
# Now we can draw arrows from the first column to the second
arrows(rep(1.02, len.1), 1:len.1, rep(1.98, len.2), a.to.b,
length=arrow.len, angle=20, col =  ifelse(abs(1:length(a)-a.to.b) >10,'blue','black'))
par(old.par)
}
# + ranking of Duration VS time
ranked_langs <- lapply(length_defs, function(length_def) {
df <- read.csv(here('results',paste0('optimality_scores_cv_',length_def,corr_suffix,'.csv')))[-1] %>%
arrange(desc(psi))
df$language
})
pdf(here('figures',paste0('timeVSspace_ranks',corr_suffix,'.pdf')))
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
old.par <- par(mar=c(1,1,1,1))
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
old.par <- par(mar=c(1,1,1,1))
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
par(old.par)
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
dev.off()
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
# + ranking of Duration VS time
ranked_langs <- lapply(length_defs, function(length_def) {
df <- read.csv(here('results',paste0('optimality_scores_cv_',length_def,corr_suffix,'.csv')))[-1] %>%
arrange(desc(psi))
df$language
})
source('R_functions.R')
# + ranking of Duration VS time
ranked_langs <- lapply(length_defs, function(length_def) {
df <- read.csv(here('results',paste0('optimality_scores_cv_',length_def,corr_suffix,'.csv')))[-1] %>%
arrange(desc(psi))
df$language
})
pdf(here('figures',paste0('timeVSspace_ranks',corr_suffix,'.pdf')))
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
dev.off()
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
plotRanks <- function(a, b, title, labels.offset=0.1, arrow.len=0.1) {
old.par <- par(mar=c(1,1,1,1))
a <- rev(a)
b <- rev(b)
# Find the length of the vectors
len.1 <- length(a)
len.2 <- length(b)
# Plot two columns of equidistant points
plot(rep(1, len.1), 1:len.1, pch=20, cex=0.8,
xlim=c(0, 3), ylim=c(0, max(len.1, len.2)),
axes=F, xlab="", ylab="",main=title) # Remove axes and labels
points(rep(2, len.2), 1:len.2, pch=20, cex=0.8)
# Put labels next to each observation
text(rep(1-labels.offset, len.1), 1:len.1, a, cex=0.7)
text(rep(2+labels.offset, len.2), 1:len.2, b, cex=0.7)
# Map where the elements of a are in b
a.to.b <- match(a, b)
# Now we can draw arrows from the first column to the second
arrows(rep(1.02, len.1), 1:len.1, rep(1.98, len.2), a.to.b,
length=arrow.len, angle=20, col =  ifelse(abs(1:length(a)-a.to.b) >10,'lightblue','black'))
par(old.par)
}
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
plotRanks <- function(a, b, title, labels.offset=0.1, arrow.len=0.1) {
old.par <- par(mar=c(1,1,1,1))
a <- rev(a)
b <- rev(b)
# Find the length of the vectors
len.1 <- length(a)
len.2 <- length(b)
# Plot two columns of equidistant points
plot(rep(1, len.1), 1:len.1, pch=20, cex=0.8,
xlim=c(0, 3), ylim=c(0, max(len.1, len.2)),
axes=F, xlab="", ylab="",main=title) # Remove axes and labels
points(rep(2, len.2), 1:len.2, pch=20, cex=0.8)
# Put labels next to each observation
text(rep(1-labels.offset, len.1), 1:len.1, a, cex=0.7)
text(rep(2+labels.offset, len.2), 1:len.2, b, cex=0.7)
# Map where the elements of a are in b
a.to.b <- match(a, b)
# Now we can draw arrows from the first column to the second
arrows(rep(1.02, len.1), 1:len.1, rep(1.98, len.2), a.to.b,
length=arrow.len, angle=20, col =  ifelse(abs(1:length(a)-a.to.b) >10,'blue','black'))
par(old.par)
}
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
pdf(here('figures',paste0('timeVSspace_ranks',corr_suffix,'.pdf')))
plotRanks(ranked_langs[[1]],ranked_langs[[2]], 'characters   -   duration',labels.offset = 0.3)
dev.off()
View(langs_df_cv)
## cv
langs_df_cv <- read.csv(here("data/descriptive_tables/common_voice.csv")) %>%
filter(iso_code %!in% c('jp','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'eo'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'el'), by = "iso_code") %>%
filter(dialect %!in% c('vallader','sursilv')) %>%
rows_update(tibble(iso_code = 'cnh',language = "Hakha Chin"), by = "language") %>%
rows_update(tibble(iso_code = 'sah',language = "Yakut"), by = "language")
View(langs_df_cv)
read.csv(here("data/descriptive_tables/common_voice.csv"))
read.csv(here("data/descriptive_tables/common_voice.csv")) %>%
filter(iso_code %!in% c('jp','zh'))
read.csv(here("data/descriptive_tables/common_voice.csv")) %>%
filter(iso_code %!in% c('ja','zh'))
## cv
langs_df_cv <- read.csv(here("data/descriptive_tables/common_voice.csv")) %>%
filter(iso_code %!in% c('ja','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'eo'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'el'), by = "iso_code") %>%
filter(dialect %!in% c('vallader','sursilv')) %>%
rows_update(tibble(iso_code = 'cnh',language = "Hakha Chin"), by = "language") %>%
rows_update(tibble(iso_code = 'sah',language = "Yakut"), by = "language")
46-9
read.csv(here("data/descriptive_tables/common_voice.csv"))
## cv
langs_df_cv <- read.csv(here("data/descriptive_tables/common_voice.csv")) %>%
filter(iso_code %!in% c('jpn','zho')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ina'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'ina'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'epo'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'ori'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'ell'), by = "iso_code")
langs_df_cv
read.csv(here("data/descriptive_tables/pud.csv"))
read.csv(here("data/descriptive_tables/pud.csv"))
read.csv(here("data/descriptive_tables/pud.csv"))
iso_code <- 'ita'
collection
collection <- 'cv'
collection
language <- langs_cv[ISO_cv==iso_code]
langs_cv
language
iso_code
langs_cv    <- langs_df_cv$language
ISO_cv      <- langs_df_cv$iso_code
language <- langs_cv[ISO_cv==iso_code]
language
language <- langs_cv[langs_df_cv$iso_code==iso_code]
language
read.csv(here("data/cv",paste0(iso_code,"-word.csv")), encoding = 'UTF-8')
read.csv(here("data/cv",paste0(iso_code,"-word.csv")), encoding = 'UTF-8') %>%
rename(frequency = repetitions, word = orthographic_form) %>%
arrange(desc(frequency))  %>%
mutate(characters = nchar(word), language = language)
language <- 'Chinese-strokes'
alternative <- if (stringr::str_detect(language,'-')) sub(".*-","",language) else NULL
alternative
str_suffix <- ifelse (is.null(alternative),'',paste0('_',alternative))
str_suffix
language <- 'Chinese'
alternative <- if (stringr::str_detect(language,'-')) sub(".*-","",language) else NULL
str_suffix <- ifelse (is.null(alternative),'',paste0('_',alternative))
read_language('ita','cv')
# functions  -------------------------------------------------------------------
read_language <- function(language, collection) {
if (collection == 'cv') {
iso_code <- langs_df_cv$iso_code[langs_df_cv$language==language]
read.csv(here("data/cv",paste0(iso_code,"-word.csv")), encoding = 'UTF-8') %>%
rename(frequency = repetitions, word = orthographic_form) %>%
arrange(desc(frequency))  %>%
mutate(characters = nchar(word), language = language)
} else if (collection == 'pud') {
iso_code <- langs_df_pud$iso_code[langs_df_pud$language==language]
alternative <- if (stringr::str_detect(language,'-')) sub(".*-","",language) else NULL
str_suffix <- ifelse (is.null(alternative),'',paste0('_',alternative))
read.csv(here("data/pud",paste0(iso_code,str_suffix,"_pud.csv")), encoding = 'UTF-8')[-1]
} else print('specify an available collection')
}
read_language('ita','cv')
langs_df_cv
read_language('Italian','cv')
read_language('Italian','pud')
## pud
langs_df_pud <- read.csv(here("data/descriptive_tables/pud.csv")) %>% select(-dialect)
langs_pud    <- langs_df_pud$language
## cv
langs_df_cv <- read.csv(here("data/descriptive_tables/common_voice.csv")) %>%
filter(iso_code %!in% c('jpn','zho')) %>% select(-dialect) %>%                                             # remove Chinese and Japanese
rows_update(tibble(language = "Interlingua", iso_code = 'ina'), by = "iso_code") %>%  # shorten names
rows_update(tibble(family = "Conlang", iso_code = 'ina'), by = "iso_code") %>%
rows_update(tibble(family = "Conlang", iso_code = 'epo'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'ori'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'ell'), by = "iso_code")
langs_cv    <- langs_df_cv$language
ISO_cv      <- langs_df_cv$iso_code
read_language('Italian','pud')
# + alphabet sizes
lapply(COLLS,function(collection) {
langs_df <- if (collection == 'pud') langs_df_pud else if (collection == 'cv') langs_df_cv
parameters <- lapply(langs_df$language, function(i) {
df       <- read_language(language,collection)
words    <- if (is.null(alternative)) df$word else if (alternative == 'strokes') df$word else tolower(df$romanized_form)
alphabet_size <- unique(unlist(strsplit(words, ''))) %>% length()
list("language"=language, 'A'=alphabet_size)
})
df = do.call(rbind.data.frame,parameters)
write.csv(df, here('results',paste0('alphabet_sisez_',collection,'.csv')))
})
source('R_functions.R')
# + alphabet sizes
lapply(COLLS,function(collection) {
langs_df <- if (collection == 'pud') langs_df_pud else if (collection == 'cv') langs_df_cv
parameters <- lapply(langs_df$language, function(i) {
df       <- read_language(language,collection)
words    <- if (is.null(alternative)) df$word else if (alternative == 'strokes') df$word else tolower(df$romanized_form)
alphabet_size <- unique(unlist(strsplit(words, ''))) %>% length()
list("language"=language, 'A'=alphabet_size)
})
df = do.call(rbind.data.frame,parameters)
write.csv(df, here('results',paste0('alphabet_sisez_',collection,'.csv')))
})
collection
langs_df <- if (collection == 'pud') langs_df_pud else if (collection == 'cv') langs_df_cv
# + alphabet sizes
lapply(COLLS,function(collection) {
langs_df <- if (collection == 'pud') langs_df_pud else if (collection == 'cv') langs_df_cv
parameters <- lapply(langs_df$language, function(language) {
df       <- read_language(language,collection)
words    <- if (is.null(alternative)) df$word else if (alternative == 'strokes') df$word else tolower(df$romanized_form)
alphabet_size <- unique(unlist(strsplit(words, ''))) %>% length()
list("language"=language, 'A'=alphabet_size)
})
df = do.call(rbind.data.frame,parameters)
write.csv(df, here('results',paste0('alphabet_sisez_',collection,'.csv')))
})
# + collections summary
lapply(COLLS, function(collection) {
langs_df <- if (collection == 'pud') langs_df_pud else if (collection == 'cv') langs_df_cv
sum_coll <- langs_df %>% mutate(dialect = NULL, iso_code = NULL) %>% rename(n = X.tokens, `T` = X.types)
A_coll   <- read.csv(here('results',paste0('alphabet_sisez_',collection,'.csv')))
sum_coll$A <- A_coll$A
sum_coll <- sum_coll[,c('language','family','script','A','n','T')] %>%
filter(stringr::str_detect(language,'-strokes') == F) %>% arrange(family,script,language)
write.csv(sum_coll,here('results',paste0('coll_summary_',collection,'.csv')))
print(xtable(sum_coll, type = "latex"),
file = here('latex_tables',paste0('coll_summary_',collection,".tex")),
include.rownames=FALSE,include.colnames=FALSE, only.contents = TRUE,
hline.after = c(nrow(sum_coll)))
})
collection
langs_df <- if (collection == 'pud') langs_df_pud else if (collection == 'cv') langs_df_cv
# + collections summary
lapply(COLLS, function(collection) {
langs_df <- if (collection == 'pud') langs_df_pud else if (collection == 'cv') langs_df_cv
sum_coll <- langs_df %>% mutate(dialect = NULL, iso_code = NULL) %>% rename(T = X.tokens, n = X.types)
A_coll   <- read.csv(here('results',paste0('alphabet_sisez_',collection,'.csv')))
sum_coll$A <- A_coll$A
sum_coll <- sum_coll[,c('language','family','script','A','n','T')] %>%
filter(stringr::str_detect(language,'-strokes') == F) %>% arrange(family,script,language)
write.csv(sum_coll,here('results',paste0('coll_summary_',collection,'.csv')))
print(xtable(sum_coll, type = "latex"),
file = here('latex_tables',paste0('coll_summary_',collection,".tex")),
include.rownames=FALSE,include.colnames=FALSE, only.contents = TRUE,
hline.after = c(nrow(sum_coll)))
})
View(langs_df_cv)
df <- read_language('Panjabi','cv')
sum(df$frequency)
View(df)
collection
suffix
length_def
length_def <- 'characters'
suffix       <- paste0("_",length_def)
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,corr_suffix,'.csv')))[-1]
opt_df
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,corr_suffix,'.csv')))[-1]
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
opt_df
collection <- 'pud'
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1] %>%
arrange(family,script,language)
opt_df
read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1]
# + scores for each language, collection, length_def
lapply(COLLS, function(collection) {
if (collection == 'cv') {
lapply(length_defs, function(length_def) {
suffix       <- paste0("_",length_def)
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,corr_suffix,'.csv')))[-1]
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
print(xtable(merged,type = "latex"),
file = here('latex_tables',paste0(collection,"_opt_scores",suffix,corr_suffix,".tex")),
include.rownames=FALSE, include.colnames=FALSE, only.contents = TRUE)
})
} else {
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1]
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
print(xtable(opt_df,type = "latex"),
file = here('latex_tables',paste0(collection,"_opt_scores_characters",corr_suffix,".tex")),
include.rownames=FALSE, include.colnames=FALSE, only.contents = TRUE)
}
})
# + scores for each language, collection, length_def
lapply(COLLS, function(collection) {
if (collection == 'cv') {
lapply(length_defs, function(length_def) {
suffix       <- paste0("_",length_def)
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,corr_suffix,'.csv')))[-1]
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
print(xtable(opt_df,type = "latex"),
file = here('latex_tables',paste0(collection,"_opt_scores",suffix,corr_suffix,".tex")),
include.rownames=FALSE, include.colnames=FALSE, only.contents = TRUE)
})
} else {
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1]
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
print(xtable(opt_df,type = "latex"),
file = here('latex_tables',paste0(collection,"_opt_scores_characters",corr_suffix,".tex")),
include.rownames=FALSE, include.colnames=FALSE, only.contents = TRUE)
}
})
# + scores for each language, collection, length_def
lapply(COLLS, function(collection) {
if (collection == 'cv') {
lapply(length_defs, function(length_def) {
suffix       <- paste0("_",length_def)
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,corr_suffix,'.csv')))[-1]
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
print(xtable(opt_df,type = "latex"),
file = here('latex_tables',paste0(collection,"_opt_scores",suffix,corr_suffix,".tex")),
include.rownames=FALSE, include.colnames=FALSE, only.contents = TRUE,hline.after = c(nrow(sum_coll)))
})
} else {
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1]
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
print(xtable(opt_df,type = "latex"),
file = here('latex_tables',paste0(collection,"_opt_scores_characters",corr_suffix,".tex")),
include.rownames=FALSE, include.colnames=FALSE, only.contents = TRUE,hline.after = c(nrow(sum_coll)))
}
})
# + scores for each language, collection, length_def
lapply(COLLS, function(collection) {
if (collection == 'cv') {
lapply(length_defs, function(length_def) {
suffix       <- paste0("_",length_def)
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,corr_suffix,'.csv')))[-1]
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
print(xtable(opt_df,type = "latex"),
file = here('latex_tables',paste0(collection,"_opt_scores",suffix,corr_suffix,".tex")),
include.rownames=FALSE, include.colnames=FALSE, only.contents = TRUE,hline.after = c(nrow(opt_df)))
})
} else {
opt_df  <- read.csv(here('results',paste0('optimality_scores_',collection,'_characters',corr_suffix,'.csv')))[-1]
opt_df <- opt_df[,c('language', 'family', 'script', 'Lmin' , 'L', 'Lrand', 'corr', 'corr_min', 'eta' , 'psi' ,'omega')]
print(xtable(opt_df,type = "latex"),
file = here('latex_tables',paste0(collection,"_opt_scores_characters",corr_suffix,".tex")),
include.rownames=FALSE, include.colnames=FALSE, only.contents = TRUE,hline.after = c(nrow(opt_df)))
}
})
source('R_functions.R')
ad.csv(here('results',paste0('optimality_scores_pud_remove_vowels_kendall.csv')))[-1]
read.csv(here('results',paste0('optimality_scores_pud_remove_vowels_kendall.csv')))[-1]
