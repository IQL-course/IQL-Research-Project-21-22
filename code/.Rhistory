get_ranked_langs <- function(opt_df, metric) {
if (metric == 'omega') {
opt_df %>% arrange(desc(omega)) %>% dplyr::select(language) %>% mutate(ranking_omega = 1:nrow(opt_df))
} else if (metric == 'eta') {
opt_df %>% arrange(desc(eta))   %>% dplyr::select(language) %>% mutate(ranking_eta   = 1:nrow(opt_df))
}
}
# - 3 - Sorting languages by their degree of optimality
rank_omega <- get_ranked_langs(opt_df,'omega')$language
rank_eta   <- get_ranked_langs(opt_df,'eta')$language
plotRanks <- function(a, b, labels.offset=0.1, arrow.len=0.1,title) {
old.par <- par(mar=c(1,1,1,1))
a <- rev(a)
b <- rev(b)
# Find the length of the vectors
len.1 <- length(a)
len.2 <- length(b)
# Plot two columns of equidistant points
plot(rep(1, len.1), 1:len.1, pch=20, cex=0.8,
xlim=c(0, 3), ylim=c(0, max(len.1, len.2)),
axes=F, xlab="", ylab="",main=title) # Remove axes and labels
points(rep(2, len.2), 1:len.2, pch=20, cex=0.8)
# Put labels next to each observation
text(rep(1-labels.offset, len.1), 1:len.1, a)
text(rep(2+labels.offset, len.2), 1:len.2, b)
# Map where the elements of a are in b
a.to.b <- match(a, b)
# Now we can draw arrows from the first column to the second
arrows(rep(1.02, len.1), 1:len.1, rep(1.98, len.2), a.to.b,
length=arrow.len, angle=20)
par(old.par)
}
plotRanks(rank_eta, rank_omega, labels.offset=0.35, title="Eta  -  Omega")
getwd()
source('R_functions.R')
# - 0 - Checks on data
# + SD AND MEAN: coefficient of variation
df <- read.csv(here('results','coefficient_variation.csv'))
# checks on data - coefficient of variation in cv
rows <- lapply(1:length(ISO_cv), function(i) {
iso_code <- ISO_cv[i]
dialect  <- dialects_cv[i]
read_language(iso_code,'cv',dialect) %>%
summarise(iso_code,dialect,meanDuration,stDevDuration,coeff_var = stDevDuration/meanDuration)
})
rows
langs_df_cv
## cv
langs_df_cv <- read.csv(here("explanatory_tables/common_voice.csv")) %>% filter(iso_code %!in% c('ja','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code")
langs_df_cv
## cv
langs_df_cv <- read.csv(here("explanatory_tables/common_voice.csv")) %>% filter(iso_code %!in% c('ja','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code")
langs_df_cv
## cv
langs_df_cv <- read.csv(here("explanatory_tables/common_voice.csv")) %>% filter(iso_code %!in% c('ja','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'el'), by = "iso_code")
langs_cv    <- langs_df_cv$language
ISO_cv      <- langs_df_cv$iso_code
dialects_cv <- langs_df_cv$dialect
labs_cv <- langs_cv; names(labs_cv) <- ISO_cv
# checks on data - coefficient of variation in cv
rows <- lapply(1:length(ISO_cv), function(i) {
iso_code <- ISO_cv[i]
dialect  <- dialects_cv[i]
read_language(iso_code,'cv',dialect) %>%
summarise(language,meanDuration,stDevDuration,coeff_var = stDevDuration/meanDuration)
})
df <- do.call(rbind,rows)
write.csv(df, here('results','coefficient_variation.csv'))
# - 0 - Checks on data
# + SD AND MEAN: coefficient of variation
df <- read.csv(here('results','coefficient_variation.csv'))
# functions
read_language <- function(iso_code, collection, dialect = NULL, pud_strokes = T) {
# if no dialect is specified and it's unique for the language, it will be inferred
# specify the desired dialect if this is not unique
if (collection == 'cv') {
if (is.null(dialect)) dialect <- dialects_cv[ISO_cv==iso_code]
dialect  <- ifelse(dialect != '',paste0('-',dialect),'')
read.csv(here("code/common-voice-forced-alignment",paste0(iso_code,dialect,"-word.csv"))) %>%
arrange(desc(repetitions)) %>% filter(orthographic_form %!in% c('','<unk>')) %>%
rename(frequency = repetitions, word = orthographic_form) %>%
mutate(n_chars = nchar(word), language = paste0(language,dialect))
} else if (collection == 'pud') {
str_suffix <- ifelse(pud_strokes == T & iso_code %in% c('zho','jpn'),'_strokes','')
read.csv(here("data/pud/",paste0(iso_code,"_pud",str_suffix,".csv")))[-1]
} else print('specify an available collection')
}
source('R_functions.R')
# checks on data - coefficient of variation in cv
rows <- lapply(1:length(ISO_cv), function(i) {
iso_code <- ISO_cv[i]
dialect  <- dialects_cv[i]
read_language(iso_code,'cv',dialect) %>%
summarise(language,meanDuration,stDevDuration,coeff_var = stDevDuration/meanDuration)
})
function (..., skipCalls = 0, frame = parent.frame())
read_language('it','cv')
# functions
read_language <- function(iso_code, collection, dialect = NULL, pud_strokes = T) {
# if no dialect is specified and it's unique for the language, it will be inferred
# specify the desired dialect if this is not unique
if (collection == 'cv') {
if (is.null(dialect)) dialect <- dialects_cv[ISO_cv==iso_code]
dialect  <- ifelse(dialect != '',paste0('-',dialect),'')
language <- langs_cv[ISO_cv==iso_code]
read.csv(here("code/common-voice-forced-alignment",paste0(iso_code,dialect,"-word.csv"))) %>%
arrange(desc(repetitions)) %>% filter(orthographic_form %!in% c('','<unk>')) %>%
rename(frequency = repetitions, word = orthographic_form) %>%
mutate(n_chars = nchar(word), language = paste0(language,dialect))
} else if (collection == 'pud') {
str_suffix <- ifelse(pud_strokes == T & iso_code %in% c('zho','jpn'),'_strokes','')
read.csv(here("data/pud/",paste0(iso_code,"_pud",str_suffix,".csv")))[-1]
} else print('specify an available collection')
}
read_language('it','cv')
source('R_functions.R')
# checks on data - coefficient of variation in cv
rows <- lapply(1:length(ISO_cv), function(i) {
iso_code <- ISO_cv[i]
dialect  <- dialects_cv[i]
read_language(iso_code,'cv',dialect) %>%
summarise(language,meanDuration,stDevDuration,coeff_var = stDevDuration/meanDuration)
})
## cv
langs_df_cv <- read.csv(here("explanatory_tables/common_voice.csv")) %>% filter(iso_code %!in% c('ja','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'el'), by = "iso_code") %>%
filter(dialect != 'vallader')
langs_df_cv
source('R_functions.R')
# checks on data - coefficient of variation in cv
rows <- lapply(1:length(ISO_cv), function(i) {
iso_code <- ISO_cv[i]
dialect  <- dialects_cv[i]
read_language(iso_code,'cv',dialect) %>%
summarise(language,meanDuration,stDevDuration,coeff_var = stDevDuration/meanDuration)
})
df <- do.call(rbind,rows)
write.csv(df, here('results','coefficient_variation.csv'))
df
cutoffs <- seq(0,0.3,0.03)
df %>% group_by(language)
df %>% group_by(language) %>% filter(coeff_var<=cutoff)
cutoff <- 0.3
df %>% group_by(language) %>% filter(coeff_var<=cutoff)
df %>% group_by(language) %>% filter(coeff_var<=cutoff) %>% summarise(retained = n())
df %>% group_by(language) %>% summarise(total_lang = n())
df %>% group_by(language) %>% mutate(total_lang = n())
df %>% group_by(language) %>% mutate(total_lang = n()) %>%
filter(coeff_var<=cutoff) %>% summarise(retained = n()/total_lang)
df %>% group_by(language) %>% mutate(total_lang = n()) %>%
filter(coeff_var<=cutoff) %>% summarise(retained = n()/total_lang) %>% unique()
share_retained_data <- sapply(cutoffs, function(cutoff) {
df %>% group_by(language) %>% mutate(total_lang = n()) %>%
filter(coeff_var<=cutoff) %>% summarise(retained = n()/total_lang) %>% unique()
} )
share_retained_data
share_retained_data <- lapply(cutoffs, function(cutoff) {
df %>% group_by(language) %>% mutate(total_lang = n()) %>%
filter(coeff_var<=cutoff) %>% summarise(retained = n()/total_lang) %>% unique()
} )
share_retained_data
df_retained <- df %>% group_by(language) %>% mutate(total_lang = n()) %>%
filter(coeff_var<=cutoff) %>% summarise(retained = n()/total_lang) %>% unique()
df_retained
ggplot(df_retained) + geom_bar(aes(language,retained),stat='identity') + labs(title=paste0('Cutoff:',cutoff))
ggplot(df_retained) + geom_bar(aes(language,retained),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(df_retained) + geom_bar(aes(language,retained),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) + coord_flip() +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(df_retained) + geom_bar(aes(language,retained),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) + coord_flip() #+
ggplot(df_retained) + geom_bar(aes(language,retained, color=language),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) + coord_flip()
ggplot(df_retained) + geom_bar(aes(language,retained,color=retained),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) + coord_flip()
ggplot(df_retained) + geom_bar(aes(language,retained,fill=retained),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) + coord_flip()
remove_at_cutoff <- function(cutoff) {
df <- read.csv(here('results','coefficient_variation.csv'))
df_retained <- df %>% group_by(language) %>% mutate(total_lang = n()) %>%
filter(coeff_var<=cutoff) %>% summarise(retained = n()/total_lang) %>% unique()
ggplot(df_retained) + geom_bar(aes(language,retained,fill=retained),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) + coord_flip()
}
remove_at_cutoff(0.25)
ggplot(df_retained) + geom_bar(aes(language,retained,fill=retained),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) + coord_flip() + geom_hline(yintercept = min(retained))
# language level
remove_at_cutoff <- function(cutoff) {
df <- read.csv(here('results','coefficient_variation.csv'))
df_retained <- df %>% group_by(language) %>% mutate(total_lang = n()) %>%
filter(coeff_var<=cutoff) %>% summarise(retained = n()/total_lang) %>% unique()
ggplot(df_retained) + geom_bar(aes(language,retained,fill=retained),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) + coord_flip() +
geom_hline(yintercept = min(df_retained$retained))
}
# language level
remove_at_cutoff <- function(cutoff) {
df <- read.csv(here('results','coefficient_variation.csv'))
df_retained <- df %>% group_by(language) %>% mutate(total_lang = n()) %>%
filter(coeff_var<=cutoff) %>% summarise(retained = n()/total_lang) %>% unique()
ggplot(df_retained) + geom_bar(aes(language,retained,fill=retained),stat='identity') +
labs(title=paste0('Cutoff: ',cutoff)) + coord_flip() +
geom_hline(yintercept = min(df_retained$retained),color='red',linetype='dashed')
}
remove_at_cutoff(0.2)
cutoffs <- seq(0.1,0.3,0.05)
cutoffs
cutoffs <- seq(0.2,0.3,0.05)
cutoffs
cutoffs <- seq(0.15,0.3,0.05)
remove_at_cutoff(0.2)
paste0('CV_retained_at_',cutoff,'.pdf')
cutoffs
lapply(cutoffs, function(cutoff) {
remove_at_cutoff(cutoff)
ggsave(here('figures', paste0('CV_retained_at_',cutoff,'.pdf')))
})
## cv
langs_df_cv <- read.csv(here("explanatory_tables/common_voice.csv")) %>% filter(iso_code %!in% c('ja','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'el'), by = "iso_code")
langs_cv    <- langs_df_cv$language
langs_cv
langs_df_cv
rm_df <- read.csv(here("code/common-voice-forced-alignment",paste0("rm-word.csv")))
rm_df
rm_df <- read.csv(here("code/common-voice-forced-alignment",paste0("rm-word.csv")))%>%
filter(orthographic_form %!in% c('','<unk>'))
nrow(rm_df)
sum(rm_df$repetitions)
## cv
langs_df_cv <- read.csv(here("explanatory_tables/common_voice.csv")) %>% filter(iso_code %!in% c('ja','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'el'), by = "iso_code") %>%
filter(dialect != 'vallader') %>%
rows_update(tibble(X.types = 9801, X.types = 44192, iso_code = 'rm'), by = "iso_code")
## cv
langs_df_cv <- read.csv(here("explanatory_tables/common_voice.csv")) %>% filter(iso_code %!in% c('ja','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'el'), by = "iso_code") %>%
filter(dialect != 'vallader') %>%
rows_update(tibble(X.types = 9801, iso_code = 'rm'), by = "iso_code") %>%
rows_update(tibble(X.types = 44192, iso_code = 'rm'), by = "iso_code")
langs_df_cv
## cv
langs_df_cv <- read.csv(here("explanatory_tables/common_voice.csv")) %>% filter(iso_code %!in% c('ja','zh')) %>%
rows_update(tibble(language = "Interlingua", iso_code = 'ia'), by = "iso_code") %>%
rows_update(tibble(language = "Oriya", iso_code = 'or'), by = "iso_code") %>%
rows_update(tibble(language = "Modern Greek", iso_code = 'el'), by = "iso_code") %>%
filter(dialect != 'vallader') %>%
rows_update(tibble(X.types = 9801, iso_code = 'rm'), by = "iso_code") %>%
rows_update(tibble(X.types = 44192, iso_code = 'rm'), by = "iso_code") %>%
rows_update(tibble(dialect = '', iso_code = 'rm'), by = "iso_code")
langs_df_cv
langs_cv    <- langs_df_cv$language
ISO_cv      <- langs_df_cv$iso_code
dialects_cv <- langs_df_cv$dialect
labs_cv <- langs_cv; names(labs_cv) <- ISO_cv
dialects_cv
# functions
read_language <- function(iso_code, collection, dialect = NULL, pud_strokes = T) {
# if no dialect is specified and it's unique for the language, it will be inferred
# specify the desired dialect if this is not unique
if (collection == 'cv') {
if (is.null(dialect)) dialect <- dialects_cv[ISO_cv==iso_code]
dialect  <- ifelse(dialect != '',paste0('-',dialect),'')
language <- langs_cv[ISO_cv==iso_code]
read.csv(here("code/common-voice-forced-alignment",paste0(iso_code,dialect,"-word.csv"))) %>%
arrange(desc(repetitions)) %>% filter(orthographic_form %!in% c('','<unk>')) %>%
rename(frequency = repetitions, word = orthographic_form) %>%
mutate(n_chars = nchar(word), language = paste0(language,dialect))
} else if (collection == 'pud') {
str_suffix <- ifelse(pud_strokes == T & iso_code %in% c('zho','jpn'),'_strokes','')
read.csv(here("data/pud/",paste0(iso_code,"_pud",str_suffix,".csv")))[-1]
} else print('specify an available collection')
}
source('R_functions.R')
source('R_functions.R')
# checks on data - coefficient of variation in cv
rows <- lapply(1:length(ISO_cv), function(i) {
iso_code <- ISO_cv[i]
dialect  <- dialects_cv[i]
read_language(iso_code,'cv',dialect) %>%
summarise(language,meanDuration,stDevDuration,coeff_var = stDevDuration/meanDuration)
})
df <- do.call(rbind,rows)
write.csv(df, here('results','coefficient_variation.csv'))
# language level
cutoffs <- seq(0.15,0.3,0.05)
lapply(cutoffs, function(cutoff) {
remove_at_cutoff(cutoff)
ggsave(here('figures', paste0('CV_retained_at_',cutoff,'.pdf')))
})
# - 0 - Checks on data
# + SD AND MEAN
# global
df <- read.csv(here('results','coefficient_variation.csv'))
cutoffs <- seq(0,0.3,0.03)
share_retained_data <- sapply(cutoffs, function(cutoff) round( nrow(filter(df,coeff_var<=cutoff))/nrow(df), 3 ) )
data.frame(cutoffs,share_retained_data) %>%
ggplot(aes(share_retained_data,cutoffs)) + geom_point() + geom_line()
ggsave(here('figures', 'coefficient_variation.pdf'))
collection <- 'cv'
length_def <- 'n_chars'
suffix       <- paste0("_",length_def)
opt_df <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,'.csv')))[-1]
L_diff_df <- opt_df %>% select(language,Lmin,L,Lrand,omega) %>% summarise(language,omega,Lmin,`Lrand-L` = Lrand-L, `L-Lmin` = L-Lmin)
L_diff_df$language <- factor(L_diff_df$language, levels = L_diff_df$language[order(L_diff_df$omega)])
source('R_functions.R')
# optimality scores and significance of relation
lapply(COLLS, function(collection) {
lapply(length_defs, function(length) {
print(paste(collection, length,sep='-'))
suffix <- ifelse(collection == 'pud','',paste0("_",length))
# - 1 - Compute Omega
print('begin to compute optimality scores')
opt_df <- compute_optimality_scores(collection,length)
write.csv(opt_df, here('results',paste0('optimality_scores_',collection,suffix,'.csv')))
# - 2 - Significance of word lengths
#print('begin to compute tau correlations')
#tau_df <- compute_tau_corr(collection,length)
#write.csv(tau_df, here('results',paste0('tau_correlation_',collection,suffix,'.csv')))
})
})
iso_codes <- if (collection == 'pud') ISO_pud else if (collection == 'cv') ISO_cv
iso_codes
i <- 1
iso_code <- iso_codes[i]
dialect  <- ifelse(collection=='pud','',dialects_cv[i])
dialect
df <- read_language(iso_code,collection,dialect) %>% mutate(rank=1:nrow(.))
# choose definition of 'length' in cv
if (collection == 'cv') {
df$length <- if (length == 'meanDuration') df$meanDuration else if (length == 'medianDuration') df$medianDuration else df$n_chars
}
length = 'meanDuration'
N_types    <- nrow(df)
p          <- df$frequency/sum(df$frequency)
Lmin       <- sum(sort(df$length)*p)                                                # min baseline
L          <- sum(df$length*p)                                                      # real value (weight by freq)
Lrand      <- sum(df$length)/N_types                                                # random baseline (unweighted)
eta        <- Lmin/L
omega      <- (Lrand-L)/(Lrand-Lmin)
list("language"=language, "Lmin"=Lmin, "L"=L, "Lrand"=Lrand, "eta"=eta,"omega"=omega)
language <- langs_cv[i]
list("language"=language, "Lmin"=Lmin, "L"=L, "Lrand"=Lrand, "eta"=eta,"omega"=omega)
dialect  <- ifelse(collection=='pud','',dialects_cv[i])
df <- read_language(iso_code,collection,dialect) %>% mutate(rank=1:nrow(.))
df
# choose definition of 'length' in cv
if (collection == 'cv') {
df$length <- if (length == 'meanDuration') df$meanDuration else if (length == 'medianDuration') df$medianDuration else df$n_chars
}
N_types    <- nrow(df)
p          <- df$frequency/sum(df$frequency)
Lmin       <- sum(sort(df$length)*p)                                                # min baseline
L          <- sum(df$length*p)                                                      # real value (weight by freq)
Lrand      <- sum(df$length)/N_types                                                # random baseline (unweighted)
eta        <- Lmin/L
omega      <- (Lrand-L)/(Lrand-Lmin)
list("language"=language, "Lmin"=Lmin, "L"=L, "Lrand"=Lrand, "eta"=eta,"omega"=omega)
compute_optimality_scores <- function(collection, length = 'meanDuration') {
iso_codes <- if (collection == 'pud') ISO_pud else if (collection == 'cv') ISO_cv
res <- lapply(1:length(iso_codes), function(i) {
iso_code <- iso_codes[i]
language <- langs_cv[i]
dialect  <- ifelse(collection=='pud','',dialects_cv[i])
df <- read_language(iso_code,collection,dialect) %>% mutate(rank=1:nrow(.))
# choose definition of 'length' in cv
if (collection == 'cv') {
df$length <- if (length == 'meanDuration') df$meanDuration else if (length == 'medianDuration') df$medianDuration else df$n_chars
}
N_types    <- nrow(df)
p          <- df$frequency/sum(df$frequency)
Lmin       <- sum(sort(df$length)*p)                                                # min baseline
L          <- sum(df$length*p)                                                      # real value (weight by freq)
Lrand      <- sum(df$length)/N_types                                                # random baseline (unweighted)
eta        <- Lmin/L
omega      <- (Lrand-L)/(Lrand-Lmin)
list("language"=language, "Lmin"=Lmin, "L"=L, "Lrand"=Lrand, "eta"=eta,"omega"=omega)
})
return(do.call(rbind.data.frame,res))
}
source('R_functions.R')
# optimality scores and significance of relation
lapply(COLLS, function(collection) {
lapply(length_defs, function(length) {
print(paste(collection, length,sep='-'))
suffix <- ifelse(collection == 'pud','',paste0("_",length))
# - 1 - Compute Omega
print('begin to compute optimality scores')
opt_df <- compute_optimality_scores(collection,length)
write.csv(opt_df, here('results',paste0('optimality_scores_',collection,suffix,'.csv')))
# - 2 - Significance of word lengths
#print('begin to compute tau correlations')
#tau_df <- compute_tau_corr(collection,length)
#write.csv(tau_df, here('results',paste0('tau_correlation_',collection,suffix,'.csv')))
})
})
opt_df <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,'.csv')))[-1]
L_diff_df <- opt_df %>% select(language,Lmin,L,Lrand,omega) %>% summarise(language,omega,Lmin,`Lrand-L` = Lrand-L, `L-Lmin` = L-Lmin)
L_diff_df$language <- factor(L_diff_df$language, levels = L_diff_df$language[order(L_diff_df$omega)])
melted <- melt(L_diff_df, id.vars=c("language","omega")) %>%
mutate(masked_omega = ifelse(variable == "Lrand-L",round(omega,2),""))
melted$alphacol <- ifelse(melted$variable=="Lmin",0,1)
melted$variable <- factor(melted$variable, levels=c("Lrand-L","L-Lmin","Lmin"))
plot <- ggplot(melted,aes(x=language,y=value,fill=variable)) +
geom_bar(stat="identity",aes(alpha=alphacol)) + labs(y="difference") +
geom_text(aes(label = masked_omega, color="omega"),position = position_stack(vjust = .5)) + coord_flip() +
scale_alpha_identity()+ scale_fill_manual(values = c("#6EE1A4","#E16E9C","blue"),limits = c('Lrand-L', 'L-Lmin'))
plot
plot_omega_composition <- function(opt_df) {
L_diff_df <- opt_df %>% select(language,Lmin,L,Lrand,omega) %>% summarise(language,omega,Lmin,`Lrand-L` = Lrand-L, `L-Lmin` = L-Lmin)
L_diff_df$language <- factor(L_diff_df$language, levels = L_diff_df$language[order(L_diff_df$omega)])
melted <- melt(L_diff_df, id.vars=c("language","omega")) %>%
mutate(masked_omega = ifelse(variable == "Lrand-L",round(omega,2),""))
melted$alphacol <- ifelse(melted$variable=="Lmin",0,1)
melted$variable <- factor(melted$variable, levels=c("Lrand-L","L-Lmin","Lmin"))
ggplot(melted,aes(x=language,y=value,fill=variable)) +
geom_bar(stat="identity",aes(alpha=alphacol)) + labs(y="difference") +
geom_text(aes(label = masked_omega, color="omega"),position = position_stack(vjust = .5)) + coord_flip() +
scale_alpha_identity()+ scale_fill_manual(values = c("#6EE1A4","#E16E9C","blue"),limits = c('Lrand-L', 'L-Lmin'))
}
plot_omega_composition(opt_df)
opt_df
ggplot(opt_df) + geom_bar(aes(language,omega),fill='lightblue') + coord_flip()
ggplot(opt_df) + geom_bar(aes(language,omega),stat='identity',fill='lightblue') + coord_flip()
ggplot(opt_df) + geom_bar(aes(reorder(language,omega),omega),stat='identity',fill='lightblue') + coord_flip()
ggplot(opt_df) + geom_bar(aes(reorder(language,omega),omega),stat='identity',fill='lightblue') +
coord_flip() + labs(x='language')
paste0(collection,' - ',length_def)
plot_title <- paste0(collection,' - ',length_def)
plot_omega <- function(opt_df,plot_title) {
ggplot(opt_df) + geom_bar(aes(reorder(language,omega),omega),stat='identity',fill='lightblue') +
coord_flip() + labs(x='language', title = plot_title)
}
plot_omega_composition <- function(opt_df,plot_title) {
L_diff_df <- opt_df %>% select(language,Lmin,L,Lrand,omega) %>% summarise(language,omega,Lmin,`Lrand-L` = Lrand-L, `L-Lmin` = L-Lmin)
L_diff_df$language <- factor(L_diff_df$language, levels = L_diff_df$language[order(L_diff_df$omega)])
melted <- melt(L_diff_df, id.vars=c("language","omega")) %>%
mutate(masked_omega = ifelse(variable == "Lrand-L",round(omega,2),""))
melted$alphacol <- ifelse(melted$variable=="Lmin",0,1)
melted$variable <- factor(melted$variable, levels=c("Lrand-L","L-Lmin","Lmin"))
ggplot(melted,aes(x=language,y=value,fill=variable)) +
geom_bar(stat="identity",aes(alpha=alphacol)) + labs(y="difference",title=plot_title) +
geom_text(aes(label = masked_omega, color="omega"),position = position_stack(vjust = .5)) + coord_flip() +
scale_alpha_identity()+ scale_fill_manual(values = c("#6EE1A4","#E16E9C","blue"),limits = c('Lrand-L', 'L-Lmin'))
}
plotRanks <- function(a, b, labels.offset=0.1, arrow.len=0.1,title) {
old.par <- par(mar=c(1,1,1,1))
a <- rev(a)
b <- rev(b)
# Find the length of the vectors
len.1 <- length(a)
len.2 <- length(b)
# Plot two columns of equidistant points
plot(rep(1, len.1), 1:len.1, pch=20, cex=0.8,
xlim=c(0, 3), ylim=c(0, max(len.1, len.2)),
axes=F, xlab="", ylab="",main=title) # Remove axes and labels
points(rep(2, len.2), 1:len.2, pch=20, cex=0.8)
# Put labels next to each observation
text(rep(1-labels.offset, len.1), 1:len.1, a)
text(rep(2+labels.offset, len.2), 1:len.2, b)
# Map where the elements of a are in b
a.to.b <- match(a, b)
# Now we can draw arrows from the first column to the second
arrows(rep(1.02, len.1), 1:len.1, rep(1.98, len.2), a.to.b,
length=arrow.len, angle=20)
par(old.par)
}
# OMEGA BARS
rows <- lapply(COLLS, function(collection) {
if (collection == 'cv') {
rows_cv <- lapply(length_defs, function(length_def) {
suffix       <- paste0("_",length_def)
plot_title <- paste0(collection,' - ',length_def)
opt_df <- read.csv(here('results',paste0('optimality_scores_',collection,suffix,'.csv')))[-1]
# plot 1
plot_omega(opt_df,plot_title)
ggsave(here('figures',paste0('omega_',collection,suffix,'.pdf')))
# plot 2
plot_omega_composition(opt_df,plot_title)
ggsave(here('figures',paste0('omega_composition_',collection,suffix,'.pdf')))
})
do.call(rbind,rows_cv)
} else if (collection == 'pud') {
length_def <- 'n_chars'
suffix       <- paste0("_",length_def)
plot_title <- paste0(collection,' - ',length_def)
df <- read.csv(here('results',paste0('optimality_scores_',collection,'.csv')))[-1]
# plot 1
plot_omega(opt_df,plot_title)
ggsave(here('figures',paste0('omega_',collection,suffix,'.pdf')))
# plot 2
plot_omega_composition(opt_df,plot_title)
ggsave(here('figures',paste0('omega_composition_',collection,suffix,'.pdf')))
}
})
