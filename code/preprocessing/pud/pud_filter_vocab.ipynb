{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d76238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../../../data/non_filtered/corpora/pud\\jpn_pud.csv\n",
      "./../../../data/non_filtered/corpora/pud\\jpn_pud_romaji.csv\n",
      "./../../../data/non_filtered/corpora/pud\\jpn_pud_strokes.csv\n",
      "./../../../data/non_filtered/corpora/pud\\kor_pud.csv\n",
      "./../../../data/non_filtered/corpora/pud\\zho_pud.csv\n",
      "./../../../data/non_filtered/corpora/pud\\zho_pud_pinyin.csv\n",
      "./../../../data/non_filtered/corpora/pud\\zho_pud_strokes.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from iso639 import Lang\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "txtFilters=glob.glob(\"./../../../data/filtered/alphabets/pud/*.csv\")\n",
    "csvsToAnalyze=glob.glob(\"./../../../data/non_filtered/corpora/pud/*.csv\")\n",
    "\n",
    "filterLang={}\n",
    "for txt in txtFilters:\n",
    "    with open(txt, newline='',encoding=\"utf-8\") as txtOpened:\n",
    "        pt3Name=txt.split(\"-\")[0].split(\"\\\\\")[1]\n",
    "        lines = txtOpened.readlines()\n",
    "        newFilter=set()\n",
    "        for line in lines[1:]:\n",
    "            elems=line.split(\",\")\n",
    "            newFilter.add(elems[0].strip(\"\\\"\"))\n",
    "        filterLang[pt3Name]=newFilter\n",
    "        \n",
    "for csvfile in csvsToAnalyze:\n",
    "    if \"jpn\" not in csvfile and \"zho\" not in csvfile and \"kor\" not in csvfile: \n",
    "        names=csvfile.split(\"\\\\\")[1].split(\"_\")[0]\n",
    "        isoLan=names\n",
    "        isoLanIdentifier=names\n",
    "        with open(\"./../../../data/filtered/corpora/pud/\"+isoLanIdentifier+\"_pud.csv\", 'w', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"\",\"word\",\"frequency\",\"n_characters\"])\n",
    "            with open(csvfile, newline='',encoding=\"utf-8\") as csvfileOpened:\n",
    "                reader = csv.reader(csvfileOpened, delimiter=',', quotechar='\"')\n",
    "                next(reader)\n",
    "                alphabetSet=filterLang[isoLanIdentifier]\n",
    "                for row in reader:\n",
    "                    valid=True\n",
    "                    for letter in row[0]:\n",
    "                        if letter not in alphabetSet:\n",
    "                            valid=False\n",
    "                            break\n",
    "                    if valid:\n",
    "                        writer.writerow(row)\n",
    "    else:\n",
    "        names=csvfile.split(\"\\\\\")[1].split(\"_\")[0]\n",
    "        isoLan=names\n",
    "        isoLanIdentifier=names\n",
    "        print(csvfile)\n",
    "        toAdd=\"\"\n",
    "        if \"strokes\" in csvfile:\n",
    "            toAdd+=\"_strokes\"\n",
    "        if \"pinyin\" in csvfile:\n",
    "            toAdd+=\"_pinyin\"\n",
    "        if \"romaji\" in csvfile:\n",
    "            toAdd+= \"_romaji\"\n",
    "        f_src = open(csvfile, 'rb')\n",
    "        f_dest = open(\"./../../../data/filtered/corpora/pud/\"+isoLanIdentifier+\"_pud\"+toAdd+\".csv\", 'wb')\n",
    "        shutil.copyfileobj(f_src,f_dest) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e3dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cihai.core import Cihai\n",
    "from pypinyin import pinyin, lazy_pinyin, Style\n",
    "import csv\n",
    "\n",
    "c = Cihai()\n",
    "if not c.unihan.is_bootstrapped:  # download and install Unihan to db\n",
    "    c.unihan.bootstrap()\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "with open('./../../../data/non_filtered/corpora/pud/zho_pud.csv', newline='',encoding=\"utf-8\") as csvfile:\n",
    "    with open(\"./../../../data/filtered/corpora/pud/zho_pud.csv\", 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"\",\"word\",\"frequency\",\"n_characters\"])\n",
    "        \n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        next(spamreader)\n",
    "        for row in spamreader:\n",
    "            word=row[0]\n",
    "            strokeSum=0\n",
    "            bad=False\n",
    "            for char in word:\n",
    "                query = c.unihan.lookup_char(char)\n",
    "                glyph = query.first()\n",
    "                if glyph!=None:\n",
    "                    strokeSum+=int(glyph.kTotalStrokes[0])\n",
    "                else:\n",
    "                    bad=True\n",
    "                    break\n",
    "            if not bad:\n",
    "                writer.writerow(row)\n",
    "    \n",
    "    \n",
    "with open('./../../../data/filtered/corpora/pud/zho_pud.csv', newline='',encoding=\"utf-8\") as csvfile:\n",
    "    with open(\"./../../../data/filtered/corpora/pud/zho_pud_strokes.csv\", 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"\",\"word\",\"frequency\",\"n_characters\"])\n",
    "        \n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        next(spamreader)\n",
    "        for row in spamreader:\n",
    "            word=row[0]\n",
    "            strokeSum=0\n",
    "            bad=False\n",
    "            for char in word:\n",
    "                query = c.unihan.lookup_char(char)\n",
    "                glyph = query.first()\n",
    "                if glyph!=None:\n",
    "                    if \" \" in glyph.kTotalStrokes:\n",
    "                        strokeSum+=int(glyph.kTotalStrokes.split(\" \")[0])\n",
    "                    else:\n",
    "                        strokeSum+=int(glyph.kTotalStrokes)\n",
    "                else:\n",
    "                    bad=True\n",
    "                    break\n",
    "            if not bad:\n",
    "                writer.writerow([word,word,row[2],strokeSum])\n",
    "\n",
    "with open('./../../../data/filtered/corpora/pud/zho_pud.csv', newline='',encoding=\"utf-8\") as csvfile:\n",
    "    with open(\"./../../../data/filtered/corpora/pud/zho_pud_pinyin.csv\", 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"\",\"word\",\"frequency\",\"n_characters\",\"romanized_form\"])\n",
    "        \n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        next(spamreader)\n",
    "        for row in spamreader:\n",
    "            word=row[0]\n",
    "            strokeSum=0\n",
    "            bad=False\n",
    "            romWord=\"\"\n",
    "            for elem in pinyin(word):\n",
    "                romWord+=elem[0]\n",
    "            strokeSum=len(romWord)\n",
    "            if not bad:\n",
    "                writer.writerow([word,word,row[2],strokeSum,romWord])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506439df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "from cihai.core import Cihai\n",
    "import string\n",
    "\n",
    "hiraganaKatakanaToStrokes={\n",
    "    \"ぁ\":3,\n",
    "    \"あ\":3,\n",
    "    \"ぃ\":2,\n",
    "    \"い\":2,\n",
    "    \"ぅ\":2,\n",
    "    \"う\":2,\n",
    "    \"ぇ\":2,\n",
    "    \"え\":2,\n",
    "    \"ぉ\":3,\n",
    "    \"お\":3,\n",
    "    \"か\":3,\n",
    "    \"が\":5,\n",
    "    \"き\":3,\n",
    "    \"ぎ\":5,\n",
    "    \"く\": 1,\n",
    "    \"ぐ\":3,\n",
    "    \"け\":3,\n",
    "    \"げ\":5,\n",
    "    \"こ\":2,\n",
    "    \"ご\":4,\n",
    "    \"さ\":2,\n",
    "    \"ざ\":4,\n",
    "    \"し\":1,\n",
    "    \"じ\":3,\n",
    "    \"す\":2,\n",
    "    \"ず\":4,\n",
    "    \"せ\":3,\n",
    "    \"ぜ\":5,\n",
    "    \"そ\":1,\n",
    "    \"ぞ\":3,\n",
    "    \"た\":4,\n",
    "    \"だ\":6,\n",
    "    \"ち\":2,\n",
    "    \"ぢ\":4,\n",
    "    \"っ\":1,\n",
    "    \"つ\":1,\n",
    "    \"づ\":3,\n",
    "    \"て\":1,\n",
    "    \"で\":3,\n",
    "    \"と\":2,\n",
    "    \"ど\":4,\n",
    "    \"な\":4,\n",
    "    \"に\":3,\n",
    "    \"ぬ\":2,\n",
    "    \"ね\":2,\n",
    "    \"の\":1,\n",
    "    \"は\":3,\n",
    "    \"ば\":5,\n",
    "    \"ぱ\":4,\n",
    "    \"ひ\":1,\n",
    "    \"び\":3,\n",
    "    \"ぴ\":2,\n",
    "    \"ふ\":4,\n",
    "    \"ぶ\":6,\n",
    "    \"ぷ\":5,\n",
    "    \"へ\":1,\n",
    "    \"べ\":3,\n",
    "    \"ぺ\":2,\n",
    "    \"ほ\":4,\n",
    "    \"ぼ\":6,\n",
    "    \"ぽ\":5,\n",
    "    \"ま\":3,\n",
    "    \"み\":1,\n",
    "    \"む\":3,\n",
    "    \"め\":2,\n",
    "    \"も\":3,\n",
    "    \"ゃ\":3,\n",
    "    \"や\":3,\n",
    "    \"ゅ\":2,\n",
    "    \"ゆ\":2,\n",
    "    \"ょ\":2,\n",
    "    \"よ\":2,\n",
    "    \"ら\":2,\n",
    "    \"り\":2,\n",
    "    \"る\":1,\n",
    "    \"れ\":2,\n",
    "    \"ろ\":1,\n",
    "    \"ゎ\":2,\n",
    "    \"わ\":2,\n",
    "    \"ゐ\":1,\n",
    "    \"ゑ\":1,\n",
    "    \"を\":3,\n",
    "    \"ん\":1,\n",
    "    \"ゔ\":4,\n",
    "    \"ゕ\":3,\n",
    "    \"ゖ\":3,\n",
    "    \"ァ\":2,\n",
    "    \"ア\":2,\n",
    "    \"ィ\":2,\n",
    "    \"イ\":2,\n",
    "    \"ゥ\":3,\n",
    "    \"ウ\":3,\n",
    "    \"ェ\":3,\n",
    "    \"エ\":3,\n",
    "    \"ォ\":3,\n",
    "    \"オ\":3,\n",
    "    \"カ\":2,\n",
    "    \"ガ\":4,\n",
    "    \"キ\":3,\n",
    "    \"ギ\":5,\n",
    "    \"ク\":2,\n",
    "    \"グ\":4,\n",
    "    \"ケ\":3,\n",
    "    \"ゲ\":5,\n",
    "    \"コ\":2,\n",
    "    \"ゴ\":4,\n",
    "    \"サ\":3,\n",
    "    \"ザ\":5,\n",
    "    \"シ\":3,\n",
    "    \"ジ\":5,\n",
    "    \"ス\":2,\n",
    "    \"ズ\":4,\n",
    "    \"セ\":2,\n",
    "    \"ゼ\":4,\n",
    "    \"ソ\":2,\n",
    "    \"ゾ\":4,\n",
    "    \"タ\":3,\n",
    "    \"ダ\":5,\n",
    "    \"チ\":3,\n",
    "    \"ヂ\":5,\n",
    "    \"ッ\":3,\n",
    "    \"ツ\":3,\n",
    "    \"ヅ\":5,\n",
    "    \"テ\":3,\n",
    "    \"デ\":5,\n",
    "    \"ト\":2,\n",
    "    \"ド\":4,\n",
    "    \"ナ\":2,\n",
    "    \"ニ\":2,\n",
    "    \"ヌ\":2,\n",
    "    \"ネ\":4,\n",
    "    \"ノ\":1,\n",
    "    \"ハ\":2,\n",
    "    \"バ\":4,\n",
    "    \"パ\":3,\n",
    "    \"ヒ\":2,\n",
    "    \"ビ\":4,\n",
    "    \"ピ\":3,\n",
    "    \"フ\":1,\n",
    "    \"ブ\":3,\n",
    "    \"プ\":2,\n",
    "    \"ヘ\":1,\n",
    "    \"ベ\":3,\n",
    "    \"ペ\":2,\n",
    "    \"ホ\":4,\n",
    "    \"ボ\":6,\n",
    "    \"ポ\":5,\n",
    "    \"マ\":2,\n",
    "    \"ミ\":3,\n",
    "    \"ム\":2,\n",
    "    \"メ\":2,\n",
    "    \"モ\":3,\n",
    "    \"ャ\":2,\n",
    "    \"ヤ\":2,\n",
    "    \"ュ\":2,\n",
    "    \"ユ\":2,\n",
    "    \"ョ\":3,\n",
    "    \"ヨ\":3,\n",
    "    \"ラ\":2,\n",
    "    \"リ\":2,\n",
    "    \"ル\":2,\n",
    "    \"レ\":1,\n",
    "    \"ロ\":3,\n",
    "    \"ヮ\":2,\n",
    "    \"ワ\":2,\n",
    "    \"ヲ\":3,\n",
    "    \"ン\":2,\n",
    "    \"ヴ\":5,\n",
    "    \"ヵ\":2,\n",
    "    \"ヶ\":3,\n",
    "    \"ヷ\":4,\n",
    "    \"ヺ\":5,\n",
    "    \"々\":3,\n",
    "    \"ー\":1\n",
    "    #\"＝\":2,\n",
    "    #\"〜\":1,\n",
    "    #\"℃\":2,\n",
    "    #\"ⅲ\":6\n",
    "\n",
    "}\n",
    "    \n",
    "    \n",
    "c = Cihai()\n",
    "if not c.unihan.is_bootstrapped:  # download and install Unihan to db\n",
    "    c.unihan.bootstrap()\n",
    "    \n",
    "\n",
    "with open('./../../../data/non_filtered/corpora/pud/jpn_pud.csv', newline='',encoding=\"utf-8\") as csvfile:\n",
    "    with open(\"./../../../data/filtered/corpora/pud/jpn_pud.csv\", 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"\",\"word\",\"frequency\",\"n_characters\"])\n",
    "        \n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        next(spamreader)\n",
    "        for row in spamreader:\n",
    "            bad=False\n",
    "            word=row[0]\n",
    "            strokeSum=0\n",
    "            for char in word:\n",
    "                if char in hiraganaKatakanaToStrokes:\n",
    "                    strokeSum+=hiraganaKatakanaToStrokes[char]\n",
    "                else:\n",
    "                    query = c.unihan.lookup_char(char)\n",
    "                    glyph = query.first()\n",
    "                    if glyph!=None:\n",
    "                        strokeSum+=int(glyph.kTotalStrokes)\n",
    "                    else:\n",
    "                        bad=True\n",
    "                        break\n",
    "            if not bad:\n",
    "                writer.writerow(row)\n",
    "                \n",
    "with open('./../../../data/filtered/corpora/pud/jpn_pud.csv', newline='',encoding=\"utf-8\") as csvfile:\n",
    "    with open(\"./../../../data/filtered/corpora/pud/jpn_pud_strokes.csv\", 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"\",\"word\",\"frequency\",\"n_characters\"])\n",
    "        \n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        next(spamreader)\n",
    "        for row in spamreader:\n",
    "            word=row[0]\n",
    "            strokeSum=0\n",
    "            bad=False\n",
    "            for char in word:\n",
    "                if char in hiraganaKatakanaToStrokes:\n",
    "                    strokeSum+=hiraganaKatakanaToStrokes[char]\n",
    "                else:\n",
    "                    query = c.unihan.lookup_char(char)\n",
    "                    glyph = query.first()\n",
    "                    if glyph!=None:\n",
    "                        if \" \" in glyph.kTotalStrokes:\n",
    "                            strokeSum+=int(glyph.kTotalStrokes.split(\" \")[0])\n",
    "                        else:\n",
    "                            strokeSum+=int(glyph.kTotalStrokes)\n",
    "                    else:\n",
    "                        bad=True\n",
    "                        break\n",
    "            if not bad:\n",
    "                writer.writerow([word,word,row[2],strokeSum])\n",
    "                \n",
    "\n",
    "    \n",
    "import cutlet\n",
    "nkatu = cutlet.Cutlet('kunrei')\n",
    "nkatu.use_foreign_spelling = False\n",
    "\n",
    "with open('./../../../data/filtered/corpora/pud/jpn_pud.csv', newline='',encoding=\"utf-8\") as csvfile:\n",
    "    with open(\"./../../../data/filtered/corpora/pud/jpn_pud_romaji.csv\", 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"\",\"word\",\"frequency\",\"n_characters\",\"romanized_form\"])\n",
    "        \n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        next(spamreader)\n",
    "        for row in spamreader:\n",
    "            word=row[0]\n",
    "            strokeSum=0\n",
    "            bad=False\n",
    "            if not bad:\n",
    "                romWord=nkatu.romaji(word).replace(\" \",\"\").lower()\n",
    "                if \"?\" not in romWord:\n",
    "                    strokeSum+=len(romWord)\n",
    "                    writer.writerow([word,word,row[2],strokeSum,romWord])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdeb15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
