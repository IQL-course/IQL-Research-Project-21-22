{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a1f357",
   "metadata": {},
   "source": [
    "# Zipf's law of compression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b5437c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os \n",
    "from conllu import parse_incr\n",
    "from collections import Counter\n",
    "from string import digits\n",
    "from csv import writer\n",
    "import pycountry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e86c6861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PUD languages\n",
    "my_list = os.listdir('ud-treebanks-v2.9')\n",
    "pud_langs = [folder[3:-4] for folder in my_list if re.search(r'\\bPUD\\b', folder)]      # get PUD languages\n",
    "pud_langs.sort()                                                                       # sort alphabetically\n",
    "\n",
    "# non latin languages\n",
    "non_latin_langs = ['Arabic','Chinese','Hindi','Japanese','Korean','Russian','Thai']\n",
    "\n",
    "# iso codes\n",
    "langs_dictionary = {}\n",
    "\n",
    "for language in pud_langs:\n",
    "    language_item = pycountry.languages.get(name=language)\n",
    "    langs_dictionary[language] = language_item.alpha_3\n",
    "\n",
    "langs_df = pd.DataFrame.from_dict(langs_dictionary, orient= \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ea7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filtering function\n",
    "regex = f'[{digits}]+'  #“。、・”«»—，）（·》《；：？％』『？」「–„–£…°€’‘¿№＝〜℃ⅲ＆１２２１６／α•／]+'\n",
    "non_lat_regex = f'[a-zA-Z]+'\n",
    "\n",
    "def is_valid(language,value):\n",
    "    # does it contain latin letters while being non latin language?\n",
    "    if (language in non_latin_langs and re.findall(non_lat_regex, value)):\n",
    "        return False\n",
    "    # contains digits or punctuation?\n",
    "    elif bool(re.findall(regex, value)):\n",
    "        return False\n",
    "    elif value == \"\":\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c75f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MAIN FUNCTION\n",
    "def freq_length_df(language):\n",
    "    folder = \"UD_\"+language+\"-PUD\"\n",
    "    print(folder)\n",
    "    [right_file] = [f for f in os.listdir(f'ud-treebanks-v2.9/{folder}') if f.endswith('.conllu')]\n",
    "    data_file = open(f'ud-treebanks-v2.9/{folder}/{right_file}', \"r\", encoding=\"utf-8\")\n",
    "\n",
    "    word_counts_raw = Counter()  \n",
    "\n",
    "    for sentence in parse_incr(data_file):\n",
    "        tokens = [token[\"form\"].lower() for token in sentence if token[\"upos\"] != 'PUNCT']\n",
    "        word_counts_raw.update(tokens)\n",
    "\n",
    "    word_counts =  {} # will hold word count and length \n",
    "\n",
    "    for word, count in word_counts_raw.items():\n",
    "        if is_valid(language, word): \n",
    "            word = word.replace(' ', '')        # replace all white spaces\n",
    "            # annotate frequency and length\n",
    "            word_counts[word] = {\n",
    "                'word': word,\n",
    "                'frequency': count,\n",
    "                'length': len(word)\n",
    "            }\n",
    "\n",
    "\n",
    "    # save frequency and length \n",
    "    df = pd.DataFrame.from_dict(word_counts, orient='index')\n",
    "    print(df.head())\n",
    "    df = df.sort_values(by=['frequency'],ascending=False)\n",
    "    df.to_csv(f'../data/pud/{langs_dictionary[language]}_pud.csv')\n",
    "    #df.to_csv(f'data/{langs_dictionary[language]}_pud.txt', index=None, sep=',', mode='a')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bc672ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UD_Arabic-PUD\n",
      "              word  frequency  length\n",
      "كتبت          كتبت          1       4\n",
      "كوري          كوري          4       4\n",
      "شولمان      شولمان          1       6\n",
      "المساعدة  المساعدة          3       8\n",
      "الخاصة      الخاصة         26       6\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/pud/ara_pud.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-041aee37eea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# BUILD DATAFRAMES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mfreq_length_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpud_langs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-041aee37eea7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# BUILD DATAFRAMES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mfreq_length_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpud_langs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-81cdd8ec4443>\u001b[0m in \u001b[0;36mfreq_length_df\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frequency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../data/pud/{langs_dictionary[language]}_pud.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m#df.to_csv(f'data/{langs_dictionary[language]}_pud.txt', index=None, sep=',', mode='a')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3385\u001b[0m         )\n\u001b[1;32m   3386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3387\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         )\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/pud/ara_pud.csv'"
     ]
    }
   ],
   "source": [
    "# BUILD DATAFRAMES\n",
    "[freq_length_df(lang) for lang in pud_langs]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90a0f26ab5e361e9bf8ebc89f017b8acb6dc036ef7070e8556f504ff8ce2a2a1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
